{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers==4.27.3\n!pip install -q accelerate==0.19.0\n!pip install -q datasets==2.12.0\n!pip install -q rouge_score\n!pip install -q sacrebleu\n!pip install -q wandb\n!pip install -q sentencepiece\n!pip install -q huggingface_hub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport transformers\nimport datasets\nfrom transformers import AutoModel,AutoTokenizer\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nfrom itertools import chain\nfrom transformers import Trainer,TrainingArguments,DataCollatorWithPadding,AutoModelForCausalLM\nimport pandas as pd\nimport re\nfrom itertools import chain\nimport numpy as np\nfrom datasets import Dataset, DatasetDict\nfrom transformers import DataCollatorWithPadding\nfrom datasets import load_metric\nfrom tqdm.autonotebook import tqdm\n\nfrom huggingface_hub import login\nlogin()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T23:46:27.173842Z","iopub.execute_input":"2023-07-07T23:46:27.174253Z","iopub.status.idle":"2023-07-07T23:46:28.005729Z","shell.execute_reply.started":"2023-07-07T23:46:27.174206Z","shell.execute_reply":"2023-07-07T23:46:28.004836Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Config:\n    checkpoint=\"EleutherAI/gpt-neo-125m\"\n    device='cuda' if torch.cuda.is_available() else 'cpu'\n\ngpt_neo_125=AutoModelForCausalLM.from_pretrained(Config.checkpoint).to(Config.device)\ntokenizer=AutoTokenizer.from_pretrained(Config.checkpoint)\nspecial_tokens={\"bos_token\":\"<|startoftext|>\",\n                \"eos_token\":\"<|endoftext|>\",\n                \"mask_token\":\"[mask]\",\n                \"pad_token\":\"[pad]\",}\n\nother_tokens=[\"<|speaker-1|>\",\"<|speaker-2|>\"]\ntokenizer.add_special_tokens(special_tokens)\ntokenizer.add_tokens(other_tokens)\n\nvocab=tokenizer.get_vocab()\ngpt_neo_125.resize_token_embeddings(len(vocab))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n## Datasets -preprocessing","metadata":{}},{"cell_type":"code","source":"# empethetic dialogue dataset from hf\n\nemp_data=load_dataset(\"empathetic_dialogues\")\n\ndef emp_in_id(data):\n    input_ids=[]\n    token_type_ids=[]\n    labels=[]\n    for idx in  tqdm(range(len(data['prompt']))):\n        sp_1=[\"<|startoftext|>\",\"<|speaker-1|>\"]+tokenizer.tokenize(data['prompt'][idx])\n        sp_2=[\"<|speaker-2|>\"]+tokenizer.tokenize(data['utterance'][idx])+[\"<|endoftext|>\"]\n        input_ids.append(tokenizer.convert_tokens_to_ids(sp_1+sp_2))\n        token_type_ids.append(tokenizer.convert_tokens_to_ids([\"<|speaker-1|>\"]*len(sp_1)+[\"<|speaker-2|>\"]*len(sp_2)))\n        labels.append(tokenizer.convert_tokens_to_ids([\"[mask]\"]*len(sp_1)+sp_2))\n    return input_ids,token_type_ids,labels\n\nemp_input_ids,emp_token_type_ids,emp_labels=emp_in_id(emp_data['test'])   \n\ndownload={'input_ids':emp_input_ids,\n 'token_type_ids':emp_token_type_ids,\n 'labels':emp_labels}\nimport pickle\npickle.dump(download,open('emp_test.p','wb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cnversation chat data  from kaggle\n\ndata = pd.read_csv(\"/kaggle/input/human-conversation-training-data/human_chat.txt\", delimiter=\"\\t\",header=None)\ndata.columns=['chats']\nchats=data['chats'].tolist()\n\npattern = r\"(?=.*\\bhi\\b)(?=.*\\bHuman 1:).*\"\nconv_ids=[idx for idx,turn in enumerate(chats) if re.match(pattern, turn, re.IGNORECASE)!=None]\ndialogues=[chats[conv_ids[idx]:conv_ids[idx+1]] for idx in range(len(conv_ids)-1)]\ndialogues=[['<|startoftext|>']+dialog+['<|endoftext|>'] for dialog in dialogues]\ndialogues=[list(map(lambda x: x.replace('Human 1:','<|speaker-1|>').replace('Human 2:','<|speaker-2|>'),turn)) for turn in dialogues]\n\n\n\ndef input_ids_map(dialog):\n    return list(map(lambda x:tokenizer.convert_tokens_to_ids(tokenizer.tokenize(x)),dialog))\n\ndef token_type_ids_map(input_id):\n    token_type_id=[[tokenizer.vocab['<|speaker-1|>']]*len(turn) if id%2==0 else [tokenizer.vocab['<|speaker-2|>']]*len(turn) for id,turn in enumerate(input_id[1:-1])]\n    token_type_id.insert(0,[tokenizer.vocab['<|speaker-1|>']])\n    token_type_id.append([tokenizer.vocab['<|speaker-2|>']])\n    return token_type_id\n\ndef labels_map(input_id):\n    label=[[tokenizer.vocab['[mask]']]*len(turn) if id%2==0 else turn for id,turn in enumerate(input_id[1:-1])]\n    label.insert(0,[tokenizer.vocab['[mask]']])\n    label.append([tokenizer.vocab['<|endoftext|>']])\n    return label\n    \ninput_ids=list(map(input_ids_map,tqdm(dialogues)))\ntoken_type_ids=list(map(token_type_ids_map,tqdm(input_ids)))\nlabels=list(map(labels_map,tqdm(input_ids)))\n\ninput_ids=[list(chain(*input_id)) for input_id in input_ids]\ntoken_type_ids=[list(chain(*token_type_id)) for token_type_id in token_type_ids]\nlabels=[list(chain(*label)) for label in labels]\n\n\n\ntrain=int(np.round(len(input_ids)*(0.8)))\nval=int(np.round(len(input_ids)*(0.1)))+train\n\n\ntrain_dataset = Dataset.from_dict({\"input_ids\":input_ids[:train],\n                        'token_type_ids':token_type_ids[:train],\n                        'labels':labels[:train]})\n\nvalidation_dataset = Dataset.from_dict({\"input_ids\":input_ids[train:val],\n                               'token_type_ids':token_type_ids[train:val],\n                               'labels':labels[train:val]})\n\ntest_dataset = Dataset.from_dict({\"input_ids\":input_ids[val:],\n                       'token_type_ids':token_type_ids[val:],\n                       'labels':labels[val:]})\n\nchat_dataset_whatsapp = DatasetDict({'train': train_dataset,\n                        'validation': validation_dataset,\n                        'test': test_dataset})","metadata":{"execution":{"iopub.status.busy":"2023-07-07T23:10:16.757844Z","iopub.execute_input":"2023-07-07T23:10:16.758922Z","iopub.status.idle":"2023-07-07T23:11:27.230901Z","shell.execute_reply.started":"2023-07-07T23:10:16.758882Z","shell.execute_reply":"2023-07-07T23:11:27.229655Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"100%|██████████| 93/93 [00:00<00:00, 523.75it/s]\n100%|██████████| 93/93 [00:44<00:00,  2.08it/s]\n100%|██████████| 93/93 [00:25<00:00,  3.65it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# daily dialogue data from hugging face \ndialog=load_dataset('daily_dialog')\n\n# adding_special_torkens\nbos_id = tokenizer.vocab['<|startoftext|>']\neos_id = tokenizer.vocab['<|endoftext|>']\nspeaker_1_id = tokenizer.vocab['<|speaker-1|>']\nspeaker_2_id = tokenizer.vocab['<|speaker-2|>']\nmask = tokenizer.vocab['[mask]']\n\n\n# preprocessing\n\ndef speaker_dialogs(data):\n    token_ids = [] \n    for dialogue in tqdm(data):\n        dialogue_ids = []\n        for ids, utterance in enumerate(dialogue):\n            tokens = tokenizer.tokenize(utterance)\n            ids = tokenizer.convert_tokens_to_ids(tokens)\n            dialogue_ids.append(ids)\n        token_ids.append(dialogue_ids)\n\n    dialogues_with_speaker_ids = []\n    for dialogue in tqdm(token_ids):\n        utterances_with_speaker_ids = []\n        for i, utterance in enumerate(dialogue):\n            if i % 2 == 0:\n                utterances_with_speaker_ids.append([speaker_1_id] + utterance)\n            else:\n                utterances_with_speaker_ids.append([speaker_2_id] + utterance)\n        dialogues_with_speaker_ids.append(utterances_with_speaker_ids)\n    return dialogues_with_speaker_ids\n\n\n\ndef all_id(all_text):\n    input_ids=[]\n    for conv in all_text:\n        conv_id=[]\n        for ids,turn in enumerate(conv):\n            if ids==0:\n                conv_id.append([bos_id]+turn)\n            elif ids==len(conv)-1:\n                conv_id.append(turn+[eos_id])\n            else:\n                conv_id.append(turn)\n                \n        input_ids.append(conv_id)\n                \n    \n    token_type_ids=[]\n    for conv in input_ids:\n        conv_id=[]\n        for ids,turn in enumerate(conv):\n            if ids%2==0:\n                conv_id.append([speaker_1_id for _ in range(len(turn))])\n            else:\n                conv_id.append([speaker_2_id for _ in range(len(turn))])\n        token_type_ids.append(conv_id)\n    \n    labels=[]\n    for conv in input_ids:\n        conv_id=[]\n        for ids,turn in enumerate(conv):\n            if ids%2==0:\n                conv_id.append([mask for _ in range(len(turn))])\n            else:\n                conv_id.append(turn)\n                \n        labels.append(conv_id)\n    return input_ids,token_type_ids,labels\n\n\ndef text_to_tokens(data):\n    dialogs_with_sp=speaker_dialogs(data)\n    input_ids,token_type_ids,labels=all_id(dialogs_with_sp)                    \n    \n    input_ids=[list(chain(*input_ids[i])) for i in range(len(input_ids))]\n    token_type_ids=[list(chain(*token_type_ids[i])) for i in range(len(token_type_ids))]\n    labels=[list(chain(*labels[i])) for i in range(len(labels))]\n    \n    return input_ids,token_type_ids,labels\n\n    \ntrain_data=dialog['train']['dialog']\nval_data=dialog['validation']['dialog']\ntest_data=dialog['test']['dialog']\n\ntrain_input_ids,train_token_type_ids,train_labels=text_to_tokens(train_data) \nval_input_ids,val_token_type_ids,val_labels=text_to_tokens(val_data) \ntest_input_ids,test_token_type_ids,test_labels=text_to_tokens(test_data) \n\n# preparing data to datasetdict format\n\ntrain_dataset = Dataset.from_dict({\"input_ids\":train_input_ids,\n                        'token_type_ids':train_token_type_ids,\n                        'labels':train_labels})\n\nvalidation_dataset = Dataset.from_dict({\"input_ids\":val_input_ids,\n                               'token_type_ids':val_token_type_ids,\n                               'labels':val_labels})\n\ntest_dataset = Dataset.from_dict({\"input_ids\":test_input_ids,\n                       'token_type_ids':test_token_type_ids,\n                       'labels':test_labels})\n\nchat_dataset_daily_dialogue = DatasetDict({'train': train_dataset,\n                        'validation': validation_dataset,\n                        'test': test_dataset})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## concat","metadata":{}},{"cell_type":"code","source":"train=int(np.round(len(input_ids)*(0.8)))\nval=int(np.round(len(input_ids)*(0.1)))+train\n\nimport pickle\nemp_train=pickle.load(open(\"/kaggle/input/empathetic-data/emp_train.p\",'rb'))\nemp_val=pickle.load(open(\"/kaggle/input/empathetic-data/emp_val.p\",'rb'))\nemp_test=pickle.load(open(\"/kaggle/input/empathetic-data/emp_test.p\",'rb'))\n\n\n\nemp_train_dataset = Dataset.from_dict({\"input_ids\":emp_train['input_ids'][:train],\n                        'token_type_ids':emp_train['token_type_ids'][:train],\n                        'labels':emp_train['labels'][:train]})\n\nemp_validation_dataset = Dataset.from_dict({\"input_ids\": emp_val['input_ids'][train:val],\n                               'token_type_ids':emp_val['token_type_ids'][train:val],\n                               'labels':emp_val['labels'][train:val]})\n\nemp_test_dataset = Dataset.from_dict({\"input_ids\":emp_test['input_ids'][val:],\n                       'token_type_ids':emp_test['token_type_ids'][va:],\n                       'labels':emp_test[\"labels\"][val:]})\n\nemp_dataset = DatasetDict({'train': emp_train_dataset,\n                        'validation': emp_validation_dataset,\n                        'test': emp_test_dataset\n                          })\n\n# chat_dataset_whatsapp\n# chat_dataset_daily_dialogue\n# emp_dataset\n\nfrom datasets import concatenate_datasets\nall_data=concatenate_datasets([chat_dataset_whatsapp[\"train\"], chat_dataset_whatsapp[\"validation\"], chat_dataset_whatsapp[\"test\"],\n                               chat_dataset_daily_dialogue[\"train\"], chat_dataset_daily_dialogue[\"validation\"], chat_dataset_daily_dialogue[\"test\"],\n                              emp_dataset[\"train\"], emp_dataset[\"validation\"], emp_dataset[\"test\"]\n                              ])\n\nall_data_shuffled=all_data.shuffle(seed=5)\nall_chat_dataset = all_data.train_test_split(test_size=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# collator function to normatize the input_size\nclass MyCollator:\n    def __init__(self, pad_token_id, max_length):\n        self.pad_token_id = pad_token_id\n        self.max_length = max_length\n\n    def __call__(self, batch):\n\n        input_ids_batch = [torch.tensor(item['input_ids'],dtype=torch.long) for item in batch]\n        token_type_ids_batch = [torch.tensor(item['token_type_ids'],dtype=torch.long) for item in batch]\n        labels_batch = [torch.tensor(item['labels'],dtype=torch.long) for item in batch]\n\n\n        input_ids_padded = torch.nn.utils.rnn.pad_sequence(input_ids_batch, batch_first=True, padding_value=self.pad_token_id)\n        input_ids_padded = input_ids_padded[:, :self.max_length]  \n\n\n        token_type_ids_padded = torch.nn.utils.rnn.pad_sequence(token_type_ids_batch, batch_first=True, padding_value=self.pad_token_id)\n        token_type_ids_padded = token_type_ids_padded[:, :self.max_length]  \n\n\n        labels_padded = torch.nn.utils.rnn.pad_sequence(labels_batch, batch_first=True, padding_value=self.pad_token_id)\n        labels_padded = labels_padded[:, :self.max_length]  \n\n        return {\n            'input_ids': input_ids_padded,\n            'token_type_ids': token_type_ids_padded,\n            'labels': labels_padded\n        }\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train ","metadata":{}},{"cell_type":"code","source":"general_training_args_concat={'output_dir':'/kaggle/working/model',\n                        'overwrite_output_dir':True, \n                        'push_to_hub':True,\n                                \n                        'num_train_epochs':10,\n                        'warmup_steps':10,\n                        'weight_decay':0.1, \n                        'logging_steps':10,\n                        'evaluation_strategy':'steps',\n                        'eval_steps':0.1,\n                        'save_steps':0.1,\n                       \n                        'optim':'adamw_torch', \n                        'save_strategy':'steps', \n                        'save_total_limit':1, \n                        'logging_dir':'/kagle/working/logs' ,\n                        'report_to':'wandb',  \n\n                        'per_device_train_batch_size':1, \n                        'per_device_eval_batch_size':1,\n                        'gradient_accumulation_steps':8}\n\ncollator=MyCollator(tokenizer.vocab['[pad]'],tokenizer.model_max_length)\ngpt_neo_concat=TrainingArguments(push_to_hub_model_id=\"gpt_neo_extended_retrain\",** general_training_args_concat)\nneo_concat_trainer=Trainer(\n    model=gpt_neo_125,\n    args=gpt_neo_concat,\n    tokenizer=tokenizer,\n    data_collator= collator,\n    train_dataset=all_chat_dataset['train'],\n    eval_dataset =all_chat_dataset['test'])\n\n# trainins and pushes model to hf hub\nneo_concat_trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# chat configuration\nclass InfConfig:\n    top_p = 0.8\n    max_length = 8\n    min_length = 2\n    max_turns = 10\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bot","metadata":{}},{"cell_type":"code","source":"bos_id = tokenizer.vocab['<|startoftext|>']\neos_id = tokenizer.vocab['<|endoftext|>']\nspeaker_1_id = tokenizer.vocab['<|speaker-1|>']\nspeaker_2_id = tokenizer.vocab['<|speaker-2|>']\nmask = tokenizer.vocab['[mask]']\n\ndef chat(model):\n    query_history = []\n    while True:\n        utterance = input('You: ')\n        if utterance == \"close_chat\":\n            break\n        \n        input_ids = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(utterance))\n        input_ids = [speaker_1_id] + input_ids\n        query_history.append(input_ids)\n        \n        if len(query_history) > InfConfig.max_turns:\n            num_exceeded = len(query_history) -  InfConfig.max_turns + 1\n            query_history = query_history[num_exceeded:]\n            \n\n        input_ids = [bos_id] + list(chain.from_iterable(query_history)) + [speaker_2_id]\n        start_sp_id = query_history[0][0]\n        next_sp_id = speaker_1_id if start_sp_id == speaker_2_id else speaker_2_id\n        token_type_ids = [[start_sp_id] * len(turn) if h % 2 == 0 else [next_sp_id] * len(turn) for h, turn in enumerate(query_history)]\n        token_type_ids = [start_sp_id] + list(chain.from_iterable(token_type_ids)) + [speaker_2_id]\n        input_len = len(input_ids)\n        input_ids = torch.LongTensor(input_ids).unsqueeze(0).to(InfConfig.device)\n        token_type_ids = torch.LongTensor(token_type_ids).unsqueeze(0).to(InfConfig.device)\n        \n        output_ids = model.generate(input_ids=input_ids, \n                                    token_type_ids=token_type_ids, \n                                    pad_token_id=tokenizer.vocab[\"[pad]\"], \n                                    do_sample=True, \n#                                     top_p=InfConfig.top_p, \n                                    max_new_tokens=InfConfig.max_length, \n                                    min_new_tokens=InfConfig.min_length,\n                                    output_hidden_states=True, \n                                    output_scores=True, \n                                    return_dict_in_generate=True).sequences\n        \n        output_ids = output_ids[0].tolist()[input_len:]\n        response = tokenizer.decode(output_ids, skip_special_tokens=True)\n        response.replace(\"<|speaker-1|>\",'').replace(\"<|speaker-2|>\",'')\n        print(f'Bot: {response}')\n        query_history.append([speaker_2_id] + tokenizer.encode(response))    \n\ninf_checkpoint=\"theothertom/gpt_neo_extended_retrain\"\nmodel=AutoModelForCausalLM.from_pretrained(inf_checkpoint).to(InfConfig.device)\nmodel=neo_concat_trainer.model\nchat(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save model manually if needed\nmodel=neo_concat_trainer.model\nmodel.save_pretrained(\"model.bin\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# utility dunctions for evaluation\ndef unk(input_id,token):\n    store=[]\n    for i,j in enumerate(input_id):\n        if j==token:\n            store.append(i)\n    return store\n\ndef map_sp(input_ids):\n    speaker_1=[]\n    speaker_2=[]\n    for input_id in tqdm(input_ids,desc=\"speaker_index_extracting\"):\n        speaker_1.append(unk(input_id,tokenizer.vocab['<|speaker-1|>']))\n        speaker_2.append(unk(input_id,tokenizer.vocab['<|speaker-2|>']))\n    return speaker_1,speaker_2\n        \n\ninput_ids=chat_dataset_daily_dialogue['test']['input_ids']\nsp_1,sp_2=map_sp(input_ids)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## evaluate","metadata":{}},{"cell_type":"code","source":"rouge_metric = load_metric(\"rouge\")\ninput_ids=chat_dataset_daily_dialogue['test']['input_ids']\ntoken_type_ids=chat_dataset_daily_dialogue['test']['token_type_ids']\nlabels=chat_dataset_daily_dialogue['test']['labels']\ndevice='cpu'\n\ndef get_metrics(input_ids,token_type_ids,model_name,device,metric_name):\n    \"\"\"\n    metric_name:\n    \"rouge\"-for rouge_metric\n    \"bleau\"-for bleau_metric\n    \n    \"\"\"\n    eval_metric = load_metric(metric_name)\n    model=AutoModelForCausalLM.from_pretrained(model_name).to(device)\n    for ids,input_id in tqdm(enumerate(input_ids[:3]),desc='running',total=len(input_ids)):\n        sp2=sp_2[ids]\n        sp1=sp_1[ids][:len(sp2)]\n        sp1.append(-1)\n        label_batch=[]\n        pred_batch=[]\n        for step in range(len(sp2)):\n            current_input=torch.LongTensor(input_id[:sp2[step]+1]).unsqueeze(0).to(device)\n            current_token_type_id=torch.LongTensor(token_type_ids[ids][:sp2[step]+1]).unsqueeze(0).to(device)\n            label_batch.append([tokenizer.decode(input_id[sp2[step]+1:sp1[step+1]])])\n\n            with torch.no_grad():\n                output= model.generate(input_ids=current_input,\n                                        token_type_ids=current_token_type_id,\n                                        pad_token_id=eos_id, \n                                        do_sample=True,\n                                        top_p=InfConfig.top_p, \n                                        max_new_tokens=InfConfig.max_length, \n                                        min_new_tokens=InfConfig.min_length,\n                                        output_hidden_states=True, \n                                        output_scores=True, \n                                        return_dict_in_generate=True).sequences\n                \n            output=output[0][len(current_input[0]):]\n            output=tokenizer.decode(output,skip_special_tokens=True)\n            output=output.replace('<|speaker-1|>','').replace('<|speaker-2|>','')\n            pred_batch.append([output])    \n        eval_metric.add_batch(predictions=pred_batch,references=label_batch)\n\n    if metric_name==\"rouge\":\n        score=eval_metric.compute()\n        score={i:score[i].mid.fmeasure for i in score.keys()}\n        return pd.DataFrame.from_dict(score, orient=\"index\", columns=[\"Value\"])\n    elif  metric_name=='sacrebleu':\n        score=eval_metric.compute(smooth_method=\"floor\", smooth_value=0)\n        score[\"precisions\"] = [np.round(p, 2) for p in score[\"precisions\"]]\n        return pd.DataFrame.from_dict(score, orient=\"index\", columns=[\"Value\"])\n            \n            \nrouge_score_neo_daily=get_metrics(input_ids,token_type_ids,\"theothertom/gpt_neo-daily_dialog\",'cpu','rouge')                    \nbleu_score_neo_daily=get_metrics(input_ids,token_type_ids,\"theothertom/gpt_neo-daily_dialog\",'cpu','sacrebleu')                    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}